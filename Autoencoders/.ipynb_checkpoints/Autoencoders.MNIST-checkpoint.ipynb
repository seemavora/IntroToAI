{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook shows implementation autoencoders and use on MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful resource: https://blog.keras.io/building-autoencoders-in-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Input, Conv2D, LSTM, MaxPool2D, UpSampling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from numpy import argmax, array_equal\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import Model\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from PIL import Image\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48000, 28, 28), (12000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train_valid, y_train_valid), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x_train_valid, y_train_valid, test_size=0.2, random_state=0)\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_validation = x_validation.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "x_train.shape, x_validation.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48000, 784), (12000, 784), (10000, 784))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape the images into flat ANN layers\n",
    "x_train = x_train.reshape(-1, 784)\n",
    "x_validation = x_validation.reshape(-1, 784)\n",
    "x_test = x_test.reshape(-1, 784)\n",
    "\n",
    "x_train.shape, x_validation.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a very simple autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(784,))   # 28*28\n",
    "encoded = layers.Dense(32, activation='relu')(input_layer)\n",
    "decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# reconstruction model:\n",
    "autoencoder = keras.Model(input_layer, decoded)\n",
    "\n",
    "# encoder model:\n",
    "encoder = keras.Model(input_layer, encoded)\n",
    "\n",
    "# decoder model:\n",
    "encoded_input = keras.Input(shape=(32,))\n",
    "decoder_layer = autoencoder.layers[-1]  # last layer of autoencoder model\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "24/24 [==============================] - 3s 80ms/step - loss: 0.5988 - val_loss: 0.4119\n",
      "Epoch 2/30\n",
      "24/24 [==============================] - 2s 73ms/step - loss: 0.3262 - val_loss: 0.2830\n",
      "Epoch 3/30\n",
      "24/24 [==============================] - 2s 67ms/step - loss: 0.2740 - val_loss: 0.2626\n",
      "Epoch 4/30\n",
      "24/24 [==============================] - 2s 73ms/step - loss: 0.2548 - val_loss: 0.2440\n",
      "Epoch 5/30\n",
      "24/24 [==============================] - 2s 73ms/step - loss: 0.2370 - val_loss: 0.2274\n",
      "Epoch 6/30\n",
      "24/24 [==============================] - 2s 65ms/step - loss: 0.2220 - val_loss: 0.2138\n",
      "Epoch 7/30\n",
      "24/24 [==============================] - 2s 66ms/step - loss: 0.2098 - val_loss: 0.2026\n",
      "Epoch 8/30\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.1989 - val_loss: 0.1922\n",
      "Epoch 9/30\n",
      "24/24 [==============================] - 2s 72ms/step - loss: 0.1895 - val_loss: 0.1840\n",
      "Epoch 10/30\n",
      "24/24 [==============================] - 2s 70ms/step - loss: 0.1822 - val_loss: 0.1775\n",
      "Epoch 11/30\n",
      "24/24 [==============================] - 3s 109ms/step - loss: 0.1763 - val_loss: 0.1722\n",
      "Epoch 12/30\n",
      "24/24 [==============================] - 2s 87ms/step - loss: 0.1712 - val_loss: 0.1676\n",
      "Epoch 13/30\n",
      "24/24 [==============================] - 3s 109ms/step - loss: 0.1666 - val_loss: 0.1631\n",
      "Epoch 14/30\n",
      "24/24 [==============================] - 3s 105ms/step - loss: 0.1625 - val_loss: 0.1592\n",
      "Epoch 15/30\n",
      "24/24 [==============================] - 2s 88ms/step - loss: 0.1587 - val_loss: 0.1556\n",
      "Epoch 16/30\n",
      "24/24 [==============================] - 2s 74ms/step - loss: 0.1552 - val_loss: 0.1522\n",
      "Epoch 17/30\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.1519 - val_loss: 0.1491\n",
      "Epoch 18/30\n",
      "24/24 [==============================] - 2s 80ms/step - loss: 0.1489 - val_loss: 0.1461\n",
      "Epoch 19/30\n",
      "24/24 [==============================] - 2s 72ms/step - loss: 0.1460 - val_loss: 0.1433\n",
      "Epoch 20/30\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.1433 - val_loss: 0.1407\n",
      "Epoch 21/30\n",
      "24/24 [==============================] - 2s 68ms/step - loss: 0.1408 - val_loss: 0.1383\n",
      "Epoch 22/30\n",
      "24/24 [==============================] - 2s 68ms/step - loss: 0.1385 - val_loss: 0.1361\n",
      "Epoch 23/30\n",
      "24/24 [==============================] - 2s 67ms/step - loss: 0.1363 - val_loss: 0.1340\n",
      "Epoch 24/30\n",
      "24/24 [==============================] - 2s 70ms/step - loss: 0.1343 - val_loss: 0.1321\n",
      "Epoch 25/30\n",
      "24/24 [==============================] - 2s 73ms/step - loss: 0.1324 - val_loss: 0.1303\n",
      "Epoch 26/30\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.1306 - val_loss: 0.1286\n",
      "Epoch 27/30\n",
      "24/24 [==============================] - 2s 65ms/step - loss: 0.1290 - val_loss: 0.1270\n",
      "Epoch 28/30\n",
      "24/24 [==============================] - 2s 68ms/step - loss: 0.1274 - val_loss: 0.1254\n",
      "Epoch 29/30\n",
      "24/24 [==============================] - 2s 64ms/step - loss: 0.1259 - val_loss: 0.1240\n",
      "Epoch 30/30\n",
      "24/24 [==============================] - 2s 67ms/step - loss: 0.1245 - val_loss: 0.1226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa39df5af10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=30,\n",
    "                batch_size=2048,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = autoencoder.predict(x_test)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(predictions[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add sparsity to the simple autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(784,))   # 28*28\n",
    "encoded = layers.Dense(32, activation='relu', activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# reconstruction model:\n",
    "autoencoder = keras.Model(input_layer, decoded)\n",
    "\n",
    "# encoder model:\n",
    "encoder = keras.Model(input_layer, encoded)\n",
    "\n",
    "# decoder model:\n",
    "encoded_input = keras.Input(shape=(32,))\n",
    "decoder_layer = autoencoder.layers[-1]  # last layer of autoencoder model\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "24/24 [==============================] - 4s 105ms/step - loss: 0.6064 - val_loss: 0.4233\n",
      "Epoch 2/30\n",
      "24/24 [==============================] - 2s 88ms/step - loss: 0.3365 - val_loss: 0.2939\n",
      "Epoch 3/30\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.2845 - val_loss: 0.2727\n",
      "Epoch 4/30\n",
      "24/24 [==============================] - 2s 91ms/step - loss: 0.2640 - val_loss: 0.2522\n",
      "Epoch 5/30\n",
      "24/24 [==============================] - 2s 79ms/step - loss: 0.2445 - val_loss: 0.2342\n",
      "Epoch 6/30\n",
      "24/24 [==============================] - 2s 85ms/step - loss: 0.2285 - val_loss: 0.2203\n",
      "Epoch 7/30\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.2162 - val_loss: 0.2098\n",
      "Epoch 8/30\n",
      "24/24 [==============================] - 2s 88ms/step - loss: 0.2068 - val_loss: 0.2015\n",
      "Epoch 9/30\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 0.1999"
     ]
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=30,\n",
    "                batch_size=2048,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = autoencoder.predict(x_test)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(predictions[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding layers to autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(784,))   # 28*28\n",
    "encoded = layers.Dense(128, activation='relu')(input_layer)\n",
    "encoded = layers.Dense(64, activation='relu')(encoded)\n",
    "encoded = layers.Dense(32, activation='relu')(encoded)\n",
    "\n",
    "decoded = layers.Dense(64, activation='relu')(encoded)\n",
    "decoded = layers.Dense(128, activation='relu')(decoded)\n",
    "decoded = layers.Dense(784, activation='sigmoid')(decoded)\n",
    "\n",
    "# reconstruction model:\n",
    "autoencoder = keras.Model(input_layer, decoded)\n",
    "\n",
    "# encoder model:\n",
    "encoder = keras.Model(input_layer, encoded)\n",
    "\n",
    "# decoder model:\n",
    "encoded_input = keras.Input(shape=(32,))\n",
    "decoder_layer = autoencoder.layers[-3]  # decoder layers of autoencoder model\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=30,\n",
    "                batch_size=2048,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = autoencoder.predict(x_test)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(predictions[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try a model with larger layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This architecture came from here: https://www.kaggle.com/shivamb/how-autoencoders-work-intro-and-usecases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input layer\n",
    "input_layer = Input(shape=(784,))   # 28*28\n",
    "\n",
    "## encoding architecture\n",
    "encode_layer1 = Dense(1500, activation='relu')(input_layer)\n",
    "encode_layer2 = Dense(1000, activation='relu')(encode_layer1)\n",
    "encode_layer3 = Dense(500, activation='relu')(encode_layer2)\n",
    "\n",
    "## latent view\n",
    "latent_view   = Dense(10, activation='sigmoid')(encode_layer3)\n",
    "\n",
    "## decoding architecture\n",
    "decode_layer1 = Dense(500, activation='relu')(latent_view)\n",
    "decode_layer2 = Dense(1000, activation='relu')(decode_layer1)\n",
    "decode_layer3 = Dense(1500, activation='relu')(decode_layer2)\n",
    "\n",
    "## output layer\n",
    "output_layer  = Dense(784)(decode_layer3)\n",
    "\n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "model.fit(x_train, x_train, epochs=30, batch_size=2048, validation_data=(x_validation, x_validation), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(predictions[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmmm, what's going on? A more complicated model doesn't seem to be doing as well as a very simple autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try adding convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape back into image matrices\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_validation = x_validation.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "x_train.shape, x_validation.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(28, 28, 1))\n",
    "\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = keras.Model(input_layer, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=30,\n",
    "                batch_size=2048,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_validation, x_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = autoencoder.predict(x_test)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(predictions[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image denoising with autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
    "x_validation_noisy = x_validation + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_validation.shape) \n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_validation_noisy = np.clip(x_validation_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(1, n + 1):\n",
    "    ax = plt.subplot(1, n, i)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# At this point the representation is (7, 7, 32)\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = keras.Model(input_layer, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=30,\n",
    "                batch_size=2048,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_validation_noisy, x_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = autoencoder.predict(x_test)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # noisy\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(predictions[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vae = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_validation_vae = x_validation.reshape((len(x_validation), np.prod(x_validation.shape[1:])))\n",
    "x_test_vae = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(784,))\n",
    "\n",
    "h = layers.Dense(64, activation='relu')(input_layer)\n",
    "z_mean = layers.Dense(2)(h)\n",
    "z_log_sigma = layers.Dense(2)(h)\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], 2),\n",
    "                              mean=0., stddev=0.1)\n",
    "    return z_mean + backend.exp(z_log_sigma) * epsilon\n",
    "\n",
    "z = layers.Lambda(sampling)([z_mean, z_log_sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder part\n",
    "encoder = keras.Model(input_layer, [z_mean, z_log_sigma, z], name='encoder')\n",
    "\n",
    "# decoder part\n",
    "latent_inputs = keras.Input(shape=(2,), name='z_sampling')\n",
    "x = layers.Dense(64, activation='relu')(latent_inputs)\n",
    "outputs = layers.Dense(784, activation='sigmoid')(x)\n",
    "decoder = keras.Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "# VAE model\n",
    "outputs = decoder(encoder(input_layer)[2])\n",
    "vae = keras.Model(input_layer, outputs, name='vae')\n",
    "\n",
    "vae.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.fit(x_train_vae, x_train_vae,\n",
    "        epochs=30,\n",
    "        batch_size=2048,\n",
    "        validation_data=(x_validation_vae, x_validation_vae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see what our data looks like in the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mean, _, _ = encoder.predict(x_test_vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(np.array(z_mean).transpose()[0], np.array(z_mean).transpose()[1], y_test)), \n",
    "                  columns =['x', 'y', 'label']) \n",
    "\n",
    "sns.scatterplot(data=df, x=\"x\", y=\"y\", hue=\"label\",palette=\"deep\",legend=\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(x=np.array(z_mean).transpose()[0], y=np.array(z_mean).transpose()[1], c=y_test, marker=\".\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
